#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•é›†å¤„ç†å™¨
å…ˆå­˜å‚¨æ•°æ®ï¼Œåå¤„ç†æµ‹è¯•é›†inputï¼Œå¬å›ç›¸ä¼¼å†…å®¹å¹¶å¡«å……instruction
"""

import json
import logging
import os
from typing import List, Dict, Any, Optional
from pathlib import Path

from ..main import NERRetrievalSystem
from ..config import ENTITY_TYPES

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TestSetProcessor:
    """
    æµ‹è¯•é›†å¤„ç†å™¨
    è´Ÿè´£å­˜å‚¨æ•°æ®å’Œå¤„ç†æµ‹è¯•é›†
    """
    
    def __init__(self, milvus_host: str = None, milvus_port: str = None, local_db_path: str = None):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            milvus_host: MilvusæœåŠ¡å™¨åœ°å€
            milvus_port: MilvusæœåŠ¡å™¨ç«¯å£
            local_db_path: æœ¬åœ°æ•°æ®åº“è·¯å¾„
        """
        self.system = NERRetrievalSystem(milvus_host, milvus_port, local_db_path)
        logger.info("æµ‹è¯•é›†å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def setup_database(self, entities_file: str, sentences_file: str, 
                      languages: List[str] = None):
        """
        è®¾ç½®æ•°æ®åº“ - å­˜å‚¨é˜¶æ®µ
        
        Args:
            entities_file: å®ä½“æ•°æ®æ–‡ä»¶è·¯å¾„
            sentences_file: å¥å­æ•°æ®æ–‡ä»¶è·¯å¾„
            languages: è¦è®¾ç½®çš„è¯­ç§åˆ—è¡¨
        """
        logger.info("å¼€å§‹æ•°æ®åº“å­˜å‚¨é˜¶æ®µ...")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(entities_file):
            raise FileNotFoundError(f"å®ä½“æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {entities_file}")
        
        if not os.path.exists(sentences_file):
            raise FileNotFoundError(f"å¥å­æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {sentences_file}")
        
        # è®¾ç½®æ•°æ®åº“
        self.system.setup_database(entities_file, sentences_file, languages)
        logger.info("æ•°æ®åº“å­˜å‚¨å®Œæˆ")
    
    def process_test_input(self, test_input: str, language: str) -> str:
        """
        å¤„ç†å•ä¸ªæµ‹è¯•è¾“å…¥ï¼Œç”Ÿæˆå¡«å……åçš„instruction
        
        Args:
            test_input: æµ‹è¯•è¾“å…¥å¥å­
            language: è¯­ç§
            
        Returns:
            str: å¡«å……åçš„å®Œæ•´instruction
        """
        logger.info(f"å¤„ç†æµ‹è¯•è¾“å…¥: {test_input} ({language})")
        
        # æ‰§è¡Œæ£€ç´¢
        result = self.system.retrieve(test_input, language)
        
        # ç”Ÿæˆinstructionï¼ˆå·²ç»åœ¨retrieveä¸­å®Œæˆï¼‰
        instruction = result["instruction_template"]
        
        # æ›¿æ¢æœ€åçš„Inputéƒ¨åˆ†ä¸ºå®é™…çš„æµ‹è¯•è¾“å…¥
        if instruction.endswith("Input: "):
            instruction = instruction + test_input
        else:
            # å¦‚æœæ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œæ‰‹åŠ¨æ·»åŠ 
            instruction = instruction.rstrip() + f"\nInput: {test_input}"
        
        return instruction
    
    def process_test_file(self, test_file: str, output_file: str, 
                         input_field: str = "input", language_field: str = "language"):
        """
        å¤„ç†æµ‹è¯•æ–‡ä»¶ï¼Œä¸ºæ¯ä¸ªinputç”Ÿæˆinstruction
        
        Args:
            test_file: æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼ˆJSON/JSONLæ ¼å¼ï¼‰
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            input_field: è¾“å…¥å­—æ®µå
            language_field: è¯­ç§å­—æ®µå
        """
        logger.info(f"å¤„ç†æµ‹è¯•æ–‡ä»¶: {test_file}")
        
        # è¯»å–æµ‹è¯•æ–‡ä»¶
        test_data = self._load_test_file(test_file)
        
        # å¤„ç†æ¯ä¸ªæµ‹è¯•æ ·æœ¬
        processed_data = []
        total = len(test_data)
        
        for i, item in enumerate(test_data, 1):
            logger.info(f"å¤„ç†è¿›åº¦: {i}/{total}")
            
            try:
                # è·å–è¾“å…¥å’Œè¯­ç§
                test_input = item.get(input_field, "")
                language = item.get(language_field, "en")  # é»˜è®¤è‹±è¯­
                
                if not test_input:
                    logger.warning(f"ç¬¬{i}ä¸ªæ ·æœ¬ç¼ºå°‘è¾“å…¥å­—æ®µ: {input_field}")
                    continue
                
                # ç”Ÿæˆinstruction
                instruction = self.process_test_input(test_input, language)
                
                # åˆ›å»ºè¾“å‡ºé¡¹
                output_item = item.copy()  # ä¿ç•™åŸæœ‰å­—æ®µ
                output_item["generated_instruction"] = instruction
                output_item["original_input"] = test_input
                output_item["language"] = language
                
                processed_data.append(output_item)
                
            except Exception as e:
                logger.error(f"å¤„ç†ç¬¬{i}ä¸ªæ ·æœ¬å¤±è´¥: {e}")
                # æ·»åŠ é”™è¯¯è®°å½•
                error_item = item.copy()
                error_item["error"] = str(e)
                error_item["generated_instruction"] = None
                processed_data.append(error_item)
        
        # ä¿å­˜ç»“æœ
        self._save_processed_data(processed_data, output_file)
        logger.info(f"å¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {output_file}")
        
        return processed_data
    
    def process_test_inputs_batch(self, test_inputs: List[Dict[str, str]], 
                                 language: str = "en") -> List[Dict[str, Any]]:
        """
        æ‰¹é‡å¤„ç†æµ‹è¯•è¾“å…¥
        
        Args:
            test_inputs: æµ‹è¯•è¾“å…¥åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«inputå­—æ®µ
            language: è¯­ç§
            
        Returns:
            List[Dict]: å¤„ç†ç»“æœåˆ—è¡¨
        """
        logger.info(f"æ‰¹é‡å¤„ç† {len(test_inputs)} ä¸ªæµ‹è¯•è¾“å…¥")
        
        results = []
        
        for i, item in enumerate(test_inputs, 1):
            logger.info(f"æ‰¹é‡å¤„ç†è¿›åº¦: {i}/{len(test_inputs)}")
            
            try:
                test_input = item.get("input", "")
                if not test_input:
                    continue
                
                instruction = self.process_test_input(test_input, language)
                
                result = {
                    "original_input": test_input,
                    "language": language,
                    "generated_instruction": instruction,
                    "index": i - 1
                }
                
                # ä¿ç•™åŸæœ‰çš„å…¶ä»–å­—æ®µ
                for key, value in item.items():
                    if key not in result:
                        result[key] = value
                
                results.append(result)
                
            except Exception as e:
                logger.error(f"æ‰¹é‡å¤„ç†ç¬¬{i}ä¸ªè¾“å…¥å¤±è´¥: {e}")
                results.append({
                    "original_input": item.get("input", ""),
                    "language": language,
                    "generated_instruction": None,
                    "error": str(e),
                    "index": i - 1
                })
        
        return results
    
    def create_instruction_for_single_input(self, test_input: str, language: str) -> Dict[str, Any]:
        """
        ä¸ºå•ä¸ªè¾“å…¥åˆ›å»ºå®Œæ•´çš„instructionä¿¡æ¯
        
        Args:
            test_input: æµ‹è¯•è¾“å…¥
            language: è¯­ç§
            
        Returns:
            Dict: å®Œæ•´çš„instructionä¿¡æ¯
        """
        # æ‰§è¡Œæ£€ç´¢è·å–è¯¦ç»†ä¿¡æ¯
        result = self.system.retrieve(test_input, language)
        
        # ç”Ÿæˆæœ€ç»ˆçš„instruction
        instruction = result["instruction_template"]
        if not instruction.endswith(test_input):
            instruction = instruction.rstrip()
            if not instruction.endswith("Input: "):
                instruction += "\nInput: "
            instruction += test_input
        
        return {
            "test_input": test_input,
            "language": language,
            "generated_instruction": instruction,
            "retrieval_statistics": result["statistics"],
            "similar_sentences": result["similar_sentences"],
            "entity_results": result["entity_results"],
            "raw_instruction_template": result["instruction_template"]
        }
    
    def _load_test_file(self, test_file: str) -> List[Dict]:
        """
        åŠ è½½æµ‹è¯•æ–‡ä»¶
        
        Args:
            test_file: æµ‹è¯•æ–‡ä»¶è·¯å¾„
            
        Returns:
            List[Dict]: æµ‹è¯•æ•°æ®åˆ—è¡¨
        """
        file_path = Path(test_file)
        
        if not file_path.exists():
            raise FileNotFoundError(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        
        data = []
        
        if file_path.suffix == '.jsonl':
            # JSONLæ ¼å¼
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if line:
                        try:
                            data.append(json.loads(line))
                        except json.JSONDecodeError as e:
                            logger.error(f"JSONLæ–‡ä»¶ç¬¬{line_num}è¡Œè§£æå¤±è´¥: {e}")
        
        elif file_path.suffix == '.json':
            # JSONæ ¼å¼
            with open(file_path, 'r', encoding='utf-8') as f:
                file_data = json.load(f)
                if isinstance(file_data, list):
                    data = file_data
                elif isinstance(file_data, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–åˆ—è¡¨
                    for key, value in file_data.items():
                        if isinstance(value, list):
                            data = value
                            break
                    if not data:
                        data = [file_data]  # å•ä¸ªå¯¹è±¡
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.suffix}")
        
        logger.info(f"ä» {test_file} åŠ è½½äº† {len(data)} ä¸ªæµ‹è¯•æ ·æœ¬")
        return data
    
    def _save_processed_data(self, data: List[Dict], output_file: str):
        """
        ä¿å­˜å¤„ç†åçš„æ•°æ®
        
        Args:
            data: å¤„ç†åçš„æ•°æ®
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        output_path = Path(output_file)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        if output_path.suffix == '.jsonl':
            # ä¿å­˜ä¸ºJSONLæ ¼å¼
            with open(output_path, 'w', encoding='utf-8') as f:
                for item in data:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
        else:
            # ä¿å­˜ä¸ºJSONæ ¼å¼
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
    
    def close(self):
        """å…³é—­ç³»ç»Ÿ"""
        self.system.close()


def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´æµç¨‹
    """
    print("ğŸ”„ æµ‹è¯•é›†å¤„ç†å®Œæ•´æµç¨‹æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–å¤„ç†å™¨
        processor = TestSetProcessor()
        
        # é˜¶æ®µ1: å­˜å‚¨æ•°æ®
        print("\nğŸ“Š é˜¶æ®µ1: å­˜å‚¨æ•°æ®åˆ°å‘é‡æ•°æ®åº“")
        entities_file = "../extracted_entities_by_language.json"
        sentences_file = "../extracted_sentences_with_ner_by_language.json"
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        if not os.path.exists(entities_file):
            print(f"âŒ å®ä½“æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {entities_file}")
            return
        
        if not os.path.exists(sentences_file):
            print(f"âŒ å¥å­æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {sentences_file}")
            return
        
        # è®¾ç½®æ•°æ®åº“ï¼ˆæ¼”ç¤ºç”¨ï¼Œåªä½¿ç”¨éƒ¨åˆ†è¯­ç§ï¼‰
        demo_languages = ["en", "de"]
        processor.setup_database(entities_file, sentences_file, demo_languages)
        print("âœ… æ•°æ®å­˜å‚¨å®Œæˆ")
        
        # é˜¶æ®µ2: å¤„ç†æµ‹è¯•è¾“å…¥
        print("\nğŸ§ª é˜¶æ®µ2: å¤„ç†æµ‹è¯•é›†è¾“å…¥")
        
        # ç¤ºä¾‹æµ‹è¯•è¾“å…¥
        test_cases = [
            {"input": "It is located in the San'a' Governorate.", "language": "en"},
            {"input": "Barack Obama was born in Hawaii.", "language": "en"},
            {"input": "Berlin ist die Hauptstadt von Deutschland.", "language": "de"},
        ]
        
        print("å¤„ç†ç¤ºä¾‹æµ‹è¯•è¾“å…¥:")
        results = []
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ“ æµ‹è¯•æ ·æœ¬ {i}:")
            print(f"   è¾“å…¥: {test_case['input']}")
            print(f"   è¯­ç§: {test_case['language']}")
            
            # ç”Ÿæˆinstruction
            instruction = processor.process_test_input(
                test_case["input"], 
                test_case["language"]
            )
            
            result = {
                "test_case": test_case,
                "generated_instruction": instruction
            }
            results.append(result)
            
            print("   âœ… Instructionç”Ÿæˆå®Œæˆ")
        
        # ä¿å­˜ç¤ºä¾‹ç»“æœ
        example_output = "test_instructions_example.json"
        with open(example_output, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç¤ºä¾‹ç»“æœå·²ä¿å­˜åˆ°: {example_output}")
        
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç”Ÿæˆçš„instruction
        print("\nğŸ“‹ ç¬¬ä¸€ä¸ªç”Ÿæˆçš„Instructionç¤ºä¾‹:")
        print("=" * 80)
        print(results[0]["generated_instruction"])
        print("=" * 80)
        
        # å…³é—­ç³»ç»Ÿ
        processor.close()
        
        print("\nğŸ‰ å®Œæ•´æµç¨‹æ¼”ç¤ºå®Œæˆ!")
        print("\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print("   1. ç¡®ä¿MilvusæœåŠ¡è¿è¡Œ")
        print("   2. å‡†å¤‡å®ä½“å’Œå¥å­æ•°æ®æ–‡ä»¶")
        print("   3. è°ƒç”¨ processor.setup_database() å­˜å‚¨æ•°æ®")
        print("   4. è°ƒç”¨ processor.process_test_input() å¤„ç†æµ‹è¯•è¾“å…¥")
        print("   5. æˆ–ä½¿ç”¨ processor.process_test_file() æ‰¹é‡å¤„ç†æ–‡ä»¶")
        
    except Exception as e:
        logger.error(f"æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()