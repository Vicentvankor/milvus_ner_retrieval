#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´ç®¡é“è¿è¡Œè„šæœ¬
æ‰§è¡Œå®Œæ•´çš„å­˜å‚¨->æ£€ç´¢->å¡«å……instructionæµç¨‹
"""

import argparse
import json
import logging
import os
import sys
import time
from pathlib import Path

from test_set_processor import TestSetProcessor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def run_complete_pipeline(entities_file: str, sentences_file: str, 
                         test_input: str, language: str = "en",
                         languages_to_setup: list = None,
                         output_file: str = None):
    """
    è¿è¡Œå®Œæ•´çš„ç®¡é“æµç¨‹
    
    Args:
        entities_file: å®ä½“æ•°æ®æ–‡ä»¶
        sentences_file: å¥å­æ•°æ®æ–‡ä»¶
        test_input: æµ‹è¯•è¾“å…¥å¥å­
        language: æµ‹è¯•è¾“å…¥çš„è¯­ç§
        languages_to_setup: è¦è®¾ç½®çš„è¯­ç§åˆ—è¡¨
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    print("ğŸš€ å¯åŠ¨å®Œæ•´ç®¡é“æµç¨‹")
    print("=" * 60)
    
    start_time = time.time()
    
    try:
        # æ­¥éª¤1: åˆå§‹åŒ–ç³»ç»Ÿ
        print("\nğŸ”§ æ­¥éª¤1: åˆå§‹åŒ–ç³»ç»Ÿ")
        processor = TestSetProcessor()
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
        # æ­¥éª¤2: å­˜å‚¨æ•°æ®åˆ°å‘é‡æ•°æ®åº“
        print("\nğŸ“Š æ­¥éª¤2: å­˜å‚¨æ•°æ®åˆ°å‘é‡æ•°æ®åº“")
        print(f"   å®ä½“æ–‡ä»¶: {entities_file}")
        print(f"   å¥å­æ–‡ä»¶: {sentences_file}")
        print(f"   ç›®æ ‡è¯­ç§: {languages_to_setup or 'å…¨éƒ¨'}")
        
        storage_start = time.time()
        processor.setup_database(entities_file, sentences_file, languages_to_setup)
        storage_time = time.time() - storage_start
        print(f"âœ… æ•°æ®å­˜å‚¨å®Œæˆ (è€—æ—¶: {storage_time:.1f}ç§’)")
        
        # æ­¥éª¤3: è¾“å…¥æµ‹è¯•å¥å­è¿›è¡Œæ£€ç´¢
        print(f"\nğŸ” æ­¥éª¤3: æ£€ç´¢å’Œç”Ÿæˆinstruction")
        print(f"   æµ‹è¯•è¾“å…¥: {test_input}")
        print(f"   è¯­ç§: {language}")
        
        retrieval_start = time.time()
        
        # è·å–è¯¦ç»†çš„æ£€ç´¢ä¿¡æ¯
        detailed_result = processor.create_instruction_for_single_input(test_input, language)
        
        retrieval_time = time.time() - retrieval_start
        print(f"âœ… æ£€ç´¢å®Œæˆ (è€—æ—¶: {retrieval_time:.1f}ç§’)")
        
        # æ­¥éª¤4: æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“‹ æ­¥éª¤4: æ£€ç´¢ç»“æœåˆ†æ")
        stats = detailed_result["retrieval_statistics"]
        print(f"   æ£€ç´¢åˆ°çš„ç›¸ä¼¼å¥å­: {stats['total_similar_sentences']} ä¸ª")
        print(f"   æ£€ç´¢åˆ°çš„ç›¸å…³å®ä½“: {stats['total_entities_found']} ä¸ª")
        print(f"   æ¶‰åŠçš„å®ä½“ç±»å‹: {stats['entity_types_found']} ç§")
        
        print(f"\n   ğŸ“ ç›¸ä¼¼å¥å­ç¤ºä¾‹ (å‰3ä¸ª):")
        for i, sent in enumerate(detailed_result["similar_sentences"][:3], 1):
            print(f"   {i}. {sent['sentence_text'][:80]}...")
            print(f"      ç›¸ä¼¼åº¦: {sent['score']:.4f}")
            print(f"      NERæ ‡ç­¾: {sent['ner_labels']}")
        
        print(f"\n   ğŸ·ï¸ æ£€ç´¢åˆ°çš„å®ä½“ç¤ºä¾‹ (æ¯ç±»å‰2ä¸ª):")
        for entity_type, entities in detailed_result["entity_results"].items():
            if entities:
                print(f"   {entity_type}:")
                for entity in entities[:2]:
                    print(f"     â€¢ {entity['entity_text']} (ç›¸ä¼¼åº¦: {entity['score']:.4f})")
        
        # æ­¥éª¤5: æ˜¾ç¤ºç”Ÿæˆçš„instruction
        print(f"\nğŸ“„ æ­¥éª¤5: ç”Ÿæˆçš„å®Œæ•´Instruction")
        print("=" * 80)
        print(detailed_result["generated_instruction"])
        print("=" * 80)
        
        # æ­¥éª¤6: ä¿å­˜ç»“æœ
        total_time = time.time() - start_time
        
        final_result = {
            "pipeline_info": {
                "entities_file": entities_file,
                "sentences_file": sentences_file,
                "test_input": test_input,
                "language": language,
                "languages_setup": languages_to_setup,
                "total_time": total_time,
                "storage_time": storage_time,
                "retrieval_time": retrieval_time
            },
            "result": detailed_result
        }
        
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(final_result, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        print(f"\nâ±ï¸ æ€»è€—æ—¶: {total_time:.1f}ç§’")
        print(f"   å­˜å‚¨é˜¶æ®µ: {storage_time:.1f}ç§’ ({storage_time/total_time*100:.1f}%)")
        print(f"   æ£€ç´¢é˜¶æ®µ: {retrieval_time:.1f}ç§’ ({retrieval_time/total_time*100:.1f}%)")
        
        processor.close()
        
        print("\nğŸ‰ å®Œæ•´ç®¡é“æµç¨‹æ‰§è¡Œå®Œæˆ!")
        
        return final_result
        
    except Exception as e:
        logger.error(f"ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
        raise
    finally:
        print("\n" + "=" * 60)


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="å®Œæ•´ç®¡é“è¿è¡Œå™¨")
    parser.add_argument("--entities-file", required=True, help="å®ä½“æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--sentences-file", required=True, help="å¥å­æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--test-input", required=True, help="æµ‹è¯•è¾“å…¥å¥å­")
    parser.add_argument("--language", default="en", help="æµ‹è¯•è¾“å…¥çš„è¯­ç§")
    parser.add_argument("--languages", nargs="+", help="è¦è®¾ç½®çš„è¯­ç§åˆ—è¡¨")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    try:
        result = run_complete_pipeline(
            entities_file=args.entities_file,
            sentences_file=args.sentences_file,
            test_input=args.test_input,
            language=args.language,
            languages_to_setup=args.languages,
            output_file=args.output
        )
        
        print("\nğŸ“‹ å¿«é€Ÿä½¿ç”¨ç¤ºä¾‹:")
        print("python run_complete_pipeline.py \\")
        print("    --entities-file ../extracted_entities_by_language.json \\")
        print("    --sentences-file ../extracted_sentences_with_ner_by_language.json \\")
        print("    --test-input \"It is located in the San'a' Governorate.\" \\")
        print("    --language en \\")
        print("    --output result.json")
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()