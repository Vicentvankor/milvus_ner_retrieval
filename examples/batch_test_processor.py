#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡æµ‹è¯•å¤„ç†å™¨
ä¸“é—¨ç”¨äºæ‰¹é‡å¤„ç†æµ‹è¯•é›†æ–‡ä»¶
"""

import argparse
import json
import logging
import os
import sys
from pathlib import Path
from typing import List, Dict, Any

from test_set_processor import TestSetProcessor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def process_test_dataset(processor: TestSetProcessor, test_file: str, 
                        output_file: str, language: str = "en",
                        input_field: str = "input", language_field: str = "language"):
    """
    å¤„ç†æµ‹è¯•æ•°æ®é›†
    
    Args:
        processor: æµ‹è¯•é›†å¤„ç†å™¨
        test_file: æµ‹è¯•æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        language: é»˜è®¤è¯­ç§
        input_field: è¾“å…¥å­—æ®µå
        language_field: è¯­ç§å­—æ®µå
    """
    logger.info(f"å¼€å§‹å¤„ç†æµ‹è¯•æ•°æ®é›†: {test_file}")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    if not os.path.exists(test_file):
        raise FileNotFoundError(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
    
    # è¯»å–æµ‹è¯•æ–‡ä»¶
    test_data = []
    file_path = Path(test_file)
    
    if file_path.suffix == '.jsonl':
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    test_data.append(json.loads(line))
    else:
        with open(file_path, 'r', encoding='utf-8') as f:
            file_content = json.load(f)
            if isinstance(file_content, list):
                test_data = file_content
            else:
                test_data = [file_content]
    
    logger.info(f"åŠ è½½äº† {len(test_data)} ä¸ªæµ‹è¯•æ ·æœ¬")
    
    # å¤„ç†æ¯ä¸ªæµ‹è¯•æ ·æœ¬
    processed_results = []
    
    for i, item in enumerate(test_data):
        logger.info(f"å¤„ç†è¿›åº¦: {i+1}/{len(test_data)}")
        
        try:
            # è·å–è¾“å…¥æ–‡æœ¬å’Œè¯­ç§
            test_input = item.get(input_field, "")
            test_language = item.get(language_field, language)
            
            if not test_input:
                logger.warning(f"æ ·æœ¬ {i+1} ç¼ºå°‘è¾“å…¥å­—æ®µ: {input_field}")
                continue
            
            # ç”Ÿæˆinstruction
            instruction = processor.process_test_input(test_input, test_language)
            
            # åˆ›å»ºç»“æœè®°å½•
            result = {
                "sample_id": i,
                "original_input": test_input,
                "language": test_language,
                "generated_instruction": instruction
            }
            
            # ä¿ç•™åŸå§‹æ•°æ®çš„å…¶ä»–å­—æ®µ
            for key, value in item.items():
                if key not in result:
                    result[f"original_{key}"] = value
            
            processed_results.append(result)
            
        except Exception as e:
            logger.error(f"å¤„ç†æ ·æœ¬ {i+1} å¤±è´¥: {e}")
            error_result = {
                "sample_id": i,
                "original_input": item.get(input_field, ""),
                "language": item.get(language_field, language),
                "generated_instruction": None,
                "error": str(e)
            }
            processed_results.append(error_result)
    
    # ä¿å­˜ç»“æœ
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(processed_results, f, ensure_ascii=False, indent=2)
    
    logger.info(f"å¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {output_file}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    successful = sum(1 for r in processed_results if r.get("generated_instruction") is not None)
    failed = len(processed_results) - successful
    
    print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print(f"   æ€»æ ·æœ¬æ•°: {len(test_data)}")
    print(f"   æˆåŠŸå¤„ç†: {successful}")
    print(f"   å¤„ç†å¤±è´¥: {failed}")
    print(f"   æˆåŠŸç‡: {successful/len(test_data)*100:.1f}%")
    
    return processed_results


def create_sample_test_file():
    """åˆ›å»ºç¤ºä¾‹æµ‹è¯•æ–‡ä»¶"""
    sample_data = [
        {
            "input": "It is located in the San'a' Governorate.",
            "language": "en",
            "expected_output": {"LOCATION": ["San'a' Governorate"]}
        },
        {
            "input": "Barack Obama was born in Hawaii and served as President.",
            "language": "en",
            "expected_output": {"PERSON": ["Barack Obama"], "LOCATION": ["Hawaii"]}
        },
        {
            "input": "Google was founded by Larry Page and Sergey Brin.",
            "language": "en",
            "expected_output": {"GROUP": ["Google"], "PERSON": ["Larry Page", "Sergey Brin"]}
        },
        {
            "input": "The Eiffel Tower is located in Paris, France.",
            "language": "en",
            "expected_output": {"FACILITY": ["Eiffel Tower"], "LOCATION": ["Paris", "France"]}
        },
        {
            "input": "Berlin ist die Hauptstadt von Deutschland.",
            "language": "de",
            "expected_output": {"LOCATION": ["Berlin", "Deutschland"]}
        }
    ]
    
    sample_file = "sample_test_data.json"
    with open(sample_file, 'w', encoding='utf-8') as f:
        json.dump(sample_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ç¤ºä¾‹æµ‹è¯•æ–‡ä»¶å·²åˆ›å»º: {sample_file}")
    return sample_file


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ‰¹é‡æµ‹è¯•é›†å¤„ç†å™¨")
    parser.add_argument("--action", choices=["setup", "process", "demo"], 
                       required=True, help="è¦æ‰§è¡Œçš„æ“ä½œ")
    parser.add_argument("--entities-file", help="å®ä½“æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--sentences-file", help="å¥å­æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--test-file", help="æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output-file", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--language", default="en", help="é»˜è®¤è¯­ç§")
    parser.add_argument("--languages", nargs="+", help="è¦è®¾ç½®çš„è¯­ç§åˆ—è¡¨")
    parser.add_argument("--input-field", default="input", help="è¾“å…¥å­—æ®µå")
    parser.add_argument("--language-field", default="language", help="è¯­ç§å­—æ®µå")
    
    args = parser.parse_args()
    
    try:
        processor = TestSetProcessor()
        
        if args.action == "setup":
            # è®¾ç½®æ•°æ®åº“
            if not args.entities_file or not args.sentences_file:
                raise ValueError("setupæ“ä½œéœ€è¦æŒ‡å®š--entities-fileå’Œ--sentences-file")
            
            print("ğŸ”§ è®¾ç½®æ•°æ®åº“...")
            processor.setup_database(
                args.entities_file, 
                args.sentences_file, 
                args.languages
            )
            print("âœ… æ•°æ®åº“è®¾ç½®å®Œæˆ")
        
        elif args.action == "process":
            # å¤„ç†æµ‹è¯•æ–‡ä»¶
            if not args.test_file or not args.output_file:
                raise ValueError("processæ“ä½œéœ€è¦æŒ‡å®š--test-fileå’Œ--output-file")
            
            print("ğŸ§ª å¤„ç†æµ‹è¯•æ–‡ä»¶...")
            process_test_dataset(
                processor=processor,
                test_file=args.test_file,
                output_file=args.output_file,
                language=args.language,
                input_field=args.input_field,
                language_field=args.language_field
            )
        
        elif args.action == "demo":
            # æ¼”ç¤ºæ¨¡å¼
            print("ğŸ­ æ¼”ç¤ºæ¨¡å¼")
            
            # åˆ›å»ºç¤ºä¾‹æµ‹è¯•æ–‡ä»¶
            sample_file = create_sample_test_file()
            
            # è®¾ç½®æ•°æ®åº“
            entities_file = "../extracted_entities_by_language.json"
            sentences_file = "../extracted_sentences_with_ner_by_language.json"
            
            if os.path.exists(entities_file) and os.path.exists(sentences_file):
                print("ğŸ”§ è®¾ç½®æ•°æ®åº“...")
                processor.setup_database(entities_file, sentences_file, ["en", "de"])
                print("âœ… æ•°æ®åº“è®¾ç½®å®Œæˆ")
                
                # å¤„ç†ç¤ºä¾‹æ–‡ä»¶
                output_file = "sample_test_results.json"
                print("ğŸ§ª å¤„ç†ç¤ºä¾‹æµ‹è¯•æ–‡ä»¶...")
                process_test_dataset(
                    processor=processor,
                    test_file=sample_file,
                    output_file=output_file,
                    language="en"
                )
                
                print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
                print(f"   - {sample_file} (ç¤ºä¾‹æµ‹è¯•æ•°æ®)")
                print(f"   - {output_file} (å¤„ç†ç»“æœ)")
            else:
                print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®åº“è®¾ç½®")
        
        processor.close()
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()