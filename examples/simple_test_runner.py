#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–æµ‹è¯•è¿è¡Œå™¨
ä¸“é—¨å¤„ç†æ‚¨æåˆ°çš„æµç¨‹ï¼šå­˜å‚¨ -> è¾“å…¥æµ‹è¯•é›†input -> å¬å› -> å¡«å……instruction
"""

import json
import logging
import sys
import os
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from test_set_processor import TestSetProcessor

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def run_your_pipeline():
    """
    è¿è¡Œæ‚¨æŒ‡å®šçš„å®Œæ•´æµç¨‹ï¼š
    1. å­˜å‚¨æ•°æ®åˆ°å‘é‡æ•°æ®åº“
    2. è¾“å…¥æµ‹è¯•å¥å­
    3. å¬å›ç›¸ä¼¼å®ä½“å’Œå¥å­
    4. å¡«å……instructionæ¨¡æ¿
    """
    
    print("ğŸš€ æ‰§è¡Œæ‚¨çš„æµ‹è¯•æµç¨‹")
    print("=" * 60)
    
    # æ‚¨çš„æµ‹è¯•è¾“å…¥
    test_input = "It is located in the San'a' Governorate."
    language = "en"
    
    print(f"ğŸ“ æµ‹è¯•è¾“å…¥: {test_input}")
    print(f"ğŸŒ è¯­ç§: {language}")
    
    try:
        # æ­¥éª¤1: åˆå§‹åŒ–å¤„ç†å™¨
        print("\nğŸ”§ æ­¥éª¤1: åˆå§‹åŒ–ç³»ç»Ÿ")
        processor = TestSetProcessor()
        
        # æ­¥éª¤2: å­˜å‚¨æ•°æ®ï¼ˆç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼‰
        entities_file = "../extracted_entities_by_language.json"
        sentences_file = "../extracted_sentences_with_ner_by_language.json"
        
        print("\nğŸ“Š æ­¥éª¤2: å­˜å‚¨æ•°æ®åˆ°å‘é‡æ•°æ®åº“")
        
        if not os.path.exists(entities_file):
            print(f"âŒ å®ä½“æ–‡ä»¶ä¸å­˜åœ¨: {entities_file}")
            print("è¯·ç¡®ä¿å·²è¿è¡Œæ•°æ®æå–è„šæœ¬ç”Ÿæˆæ­¤æ–‡ä»¶")
            return
        
        if not os.path.exists(sentences_file):
            print(f"âŒ å¥å­æ–‡ä»¶ä¸å­˜åœ¨: {sentences_file}")
            print("è¯·ç¡®ä¿å·²è¿è¡Œæ•°æ®æå–è„šæœ¬ç”Ÿæˆæ­¤æ–‡ä»¶")
            return
        
        # åªè®¾ç½®è‹±è¯­ï¼ˆåŠ å¿«æ¼”ç¤ºé€Ÿåº¦ï¼‰
        processor.setup_database(entities_file, sentences_file, [language])
        print("âœ… æ•°æ®å­˜å‚¨å®Œæˆ")
        
        # æ­¥éª¤3: è¾“å…¥æµ‹è¯•é›†çš„inputè¿›è¡Œå¬å›
        print(f"\nğŸ” æ­¥éª¤3: å¬å›ç›¸ä¼¼å†…å®¹")
        print("3.1 ä»å¥å­æ•°æ®åº“å¬å›top5ç¤ºä¾‹å¥å­...")
        print("3.2 ä»å®ä½“æ•°æ®åº“å¬å›å„å®ä½“ç±»å‹çš„top5å®ä½“...")
        
        # è·å–è¯¦ç»†æ£€ç´¢ç»“æœ
        detailed_result = processor.create_instruction_for_single_input(test_input, language)
        
        # æ˜¾ç¤ºå¬å›çš„å†…å®¹
        print("\nğŸ“ å¬å›çš„ç¤ºä¾‹å¥å­ (Top 5):")
        for i, sent in enumerate(detailed_result["similar_sentences"], 1):
            print(f"  {i}. {sent['sentence_text']}")
            print(f"     ç›¸ä¼¼åº¦: {sent['score']:.4f}")
            print(f"     NERæ ‡ç­¾: {sent['ner_labels']}")
            print()
        
        print("ğŸ·ï¸ å¬å›çš„å®ä½“ (å„ç±»å‹Top 5):")
        for entity_type, entities in detailed_result["entity_results"].items():
            if entities:
                print(f"\n  {entity_type}:")
                for j, entity in enumerate(entities, 1):
                    print(f"    {j}. {entity['entity_text']} (ç›¸ä¼¼åº¦: {entity['score']:.4f})")
        
        # æ­¥éª¤4: å¡«å……instruction
        print(f"\nğŸ“‹ æ­¥éª¤4: å¡«å……instructionæ¨¡æ¿")
        instruction = detailed_result["generated_instruction"]
        
        print("\n" + "="*80)
        print("ğŸ¯ æœ€ç»ˆç”Ÿæˆçš„å®Œæ•´Instruction:")
        print("="*80)
        print(instruction)
        print("="*80)
        
        # ä¿å­˜ç»“æœ
        result_file = "pipeline_result.json"
        result_data = {
            "test_input": test_input,
            "language": language,
            "generated_instruction": instruction,
            "retrieval_details": {
                "similar_sentences_count": len(detailed_result["similar_sentences"]),
                "total_entities_found": detailed_result["retrieval_statistics"]["total_entities_found"],
                "entity_types_found": detailed_result["retrieval_statistics"]["entity_types_found"]
            },
            "similar_sentences": detailed_result["similar_sentences"],
            "entity_results": detailed_result["entity_results"]
        }
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        
        processor.close()
        print("\nğŸ‰ æµç¨‹æ‰§è¡Œå®Œæˆ!")
        
    except Exception as e:
        logger.error(f"æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
        raise


def batch_process_test_cases():
    """æ‰¹é‡å¤„ç†å¤šä¸ªæµ‹è¯•æ ·ä¾‹"""
    print("\nğŸ”„ æ‰¹é‡å¤„ç†ç¤ºä¾‹")
    print("-" * 40)
    
    # å¤šä¸ªæµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {"input": "It is located in the San'a' Governorate.", "language": "en"},
        {"input": "Barack Obama was born in Hawaii.", "language": "en"},
        {"input": "Google was founded by Larry Page.", "language": "en"}
    ]
    
    try:
        processor = TestSetProcessor()
        
        # è®¾ç½®æ•°æ®åº“
        entities_file = "../extracted_entities_by_language.json"
        sentences_file = "../extracted_sentences_with_ner_by_language.json"
        
        if os.path.exists(entities_file) and os.path.exists(sentences_file):
            processor.setup_database(entities_file, sentences_file, ["en"])
            
            results = []
            for i, test_case in enumerate(test_cases, 1):
                print(f"\nå¤„ç†æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['input']}")
                
                instruction = processor.process_test_input(
                    test_case["input"], 
                    test_case["language"]
                )
                
                results.append({
                    "test_case": test_case,
                    "generated_instruction": instruction
                })
            
            # ä¿å­˜æ‰¹é‡ç»“æœ
            with open("batch_results.json", 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print("âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜åˆ°: batch_results.json")
            
        processor.close()
        
    except Exception as e:
        logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")


if __name__ == "__main__":
    print("é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. å•ä¸ªæµ‹è¯•æ ·ä¾‹ (æ‚¨æåˆ°çš„å…·ä½“ä¾‹å­)")
    print("2. æ‰¹é‡æµ‹è¯•æ ·ä¾‹")
    
    choice = input("\nè¯·é€‰æ‹© (1/2): ").strip()
    
    if choice == "1":
        run_your_pipeline()
    elif choice == "2":
        batch_process_test_cases()
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œé»˜è®¤å•ä¸ªæµ‹è¯•...")
        run_your_pipeline()